from numpy.linalg import inv as np_inv
from numpy.linalg import svd, det, cholesky
# from numpy.linalg import slogdet as np_slogdet
from numpy import array, trace, log, diag
from numpy import sqrt as np_sqrt
from scipy.linalg import sqrtm
from scipy.optimize import bisect, brenth, minimize_scalar, LinearConstraint, minimize
import numpy as np
import sys
from fpylll import *
from fpylll.algorithms.bkz2 import BKZReduction

ROUNDING_FACTOR = 2**64

def round_matrix_to_rational(M):
    A = matrix(ZZ, (ROUNDING_FACTOR * matrix(M)).apply_map(round))
    return matrix(QQ, A / ROUNDING_FACTOR)

def projection_matrix(A):
    """
    Construct the projection matrix orthogonally to Span(V)
    """
    S = A * A.T
    return A.T * S.inverse() * A

# Convert a 1*1 matrix into a scalar
def scal(M):
    assert M.nrows() == 1 and M.ncols() == 1, "This doesn't seem to be a scalar."
    return M[0, 0]

# Finds the square root of a matrix and its inverse as well
def square_root_inverse_degen(S, B=None, assume_full_rank=False):
    """ Compute the determinant of a symmetric matrix
    sigma (m x m) restricted to the span of the full-rank
    rectangular (k x m, k <= m) matrix V
    """
    
    if assume_full_rank:
        P = identity_matrix(S.ncols())

    elif not assume_full_rank and B is None:
        # Get an orthogonal basis for the Span of B
        V = S.echelon_form()
        V = V[:V.rank()]
        P = projection_matrix(V)

    else:
        P = projection_matrix(B)

    # make S non-degenerated by adding the complement of span(B)
    C = identity_matrix(S.ncols()) - P
    # Take matrix sqrt via SVD, then inverse
    # S = adjust_eigs(S)
    
    u, s, vh = svd(array(S + C, dtype=float))
    L_inv = np_inv(vh) @ np_inv(np_sqrt(diag(s))) @ np_inv(u)
    # L_inv = np_inv(sqrtm(array(S + C, dtype=float)))
    
    L_inv = np_inv(cholesky(array(S + C, dtype=float))).T
    L_inv = round_matrix_to_rational(L_inv)
    L = L_inv.inverse()


    # scipy outputs complex numbers, even for real valued matrices. Cast to real before rational.
    #L = round_matrix_to_rational(u @ np_sqrt(diag(s)) @ vh)

    return L, L_inv

def create_2d_plot(mie, direction, a, b):
    from copy import deepcopy
    
    # Add the lines
    major_axis_length = sqrt(mie.S.columns(0)[0][0]^2 + mie.S.columns(0)[0][1]^2)
    norm = sqrt(direction[0][0]^2 + direction[0][1]^2)
    unit_direction = direction/norm
    
    # Find the 2 points that are a distance of 'a' and 'b' away from the center
    first_center = unit_direction * a + mie.mu
    second_center = unit_direction * b + mie.mu

    # Find the points that are far away from the first and second centers in the direction of the parallel cuts.
    distance_from_center = vector(RR, [-direction[0][1], direction[0][0]]).row() * major_axis_length/norm
    
    first_line = list(first_center + distance_from_center)
    first_line.append(list(first_center - distance_from_center)[0])
    
    second_line = list(second_center + distance_from_center)
    second_line.append(list(second_center - distance_from_center)[0])
    
    # Integrate parallel cuts
    old_mie = deepcopy(mie)
    mie.integrate_parallel_cuts_hint(direction, a,b)

    p = old_mie.plot2d(1) + mie.plot2d(0)
    
    
    p += line(first_line, color = "deepskyblue")
    p += line(second_line, color = "deepskyblue")


    return p


# From the papers:
# intuitive form of ellipse: E = {c + Au : u in S^2}
# ellipoid norm form:        E = {x in R^n : <X(x-c), x-c> <= 1}
# Here, Sigma = X, and since sqrt(X) = A, it follows that
# A = sqrt({Sigma})


class MIE:
    # right now only checking for positive definite matrix, but we
    # technically should verify poitive semidefinite
    def __init__(self, S, mu):
        # check out how Hunter did this check
        if not S.is_positive_definite():
            print("ERROR: must input a positive definite matrix")
            return
        self.S = S
        self.mu = mu

    def dim(self):
        return len(list(self.mu.transpose()))

    # WARNING: this is done assuming that self.S is in the intiuitve form
    def plot2d(self, colorValue):
        p = plot([], aspect_ratio = 1)
        (sqrt_mat, sqrt_inv_mat) = square_root_inverse_degen(self.S)
        # Since the ellipse is of the form A*Ball + self.mu, we can plot the ellipse by 
        # plotting where the points of a circle map to.
        for ind in range(0,360):
            original_point = vector(RR, [cos(ind), sin(ind)]).row()
            
            # Why no transpose here??
            new_point = original_point * sqrt_mat
            new_point += self.mu
            colorVal = "black" if colorValue == 1 else "magenta"
            p2 = point(new_point,color=colorVal)
            p += p2
        return p
        
    def integrate_ineq_hint(self, v, bound):
        """
         <v, secret> <= bound
        See Eq (3.1.11), Eq. (3.1.12) in Lovasz's the Ellipsoid Method.
        """
        dim_ = self.dim()
  
        ellipsoid_norm = sqrt((v * self.S * v.transpose())[0][0])
        
        # checks if inside ellipse
        alpha = ((self.mu*v.transpose())[0][0] - bound) / ellipsoid_norm

        if alpha < -1 or alpha > 1:
            raise InvalidHint("Redundant hint! Cut outside ellipsoid!")

        if -1 <= alpha and alpha <= -1 /dim_:
            return
        
        b = (1 / ellipsoid_norm) * v * self.S.transpose()

        coeff = (1 + dim_ * alpha) / (dim_ + 1)
        print(dim_)
        coeff2 = (dim_ * dim_) / (dim_ * dim_ - 1) * (1 - alpha * alpha)

        self.mu -= coeff * b
        self.S -= (2 * coeff) / (1 + alpha) * b.transpose() * b
        self.S *= coeff2
        print(f"sssss{self.S.n()}")
        print(f"muuuu{self.mu.n()}")
    # NOTE: in the toolkit everything is done with rows instead of columns
    # go about this assuming direction is a unit vector from now on,
    # this matches the definition of what one expects when working with a
    # "direction" vector

    # but the user need not worry about this, we'll normalize it
    
    def integrate_parallel_cuts_hint(self, direction, a, b):
        if (a == b):
            print("Invalid Hint")
            return
        # the meaning of the signs here is kind of superfluous, this is just
        # to determine where everything is relative to the center of the
        # ellipsoid
        # 
        # a and b are distances from the center of the ellipsoid to the
        # two hyperplanes in the hint, along the direction of direction

        # now a and b are vectors representing the center of the ellipse
        # to the hyperplanes
        direction = direction / direction.norm()
        a = a * direction
        b = b * direction

        # there are problems if the direction is not in the column space
        # right now just error out
        try:
            self.S.solve_left(a)
            self.S.solve_left(b)
        except:
            print("a or b along direction not in column space of Sigma")
            return

        # A as above := sqrt_mat
        (sqrt_mat, sqrt_inv_mat) = square_root_inverse_degen(self.S)


        # make direction actual direction (scaled) and treat a and b as vectors from this

        # this is to accommodate for step 2 in our drawing
        # Step 2: stretch the ellipsoid into ball
        # before: E = (sqrt_mat)B_n
        # after: E = B_n
        # to get back to a ball for easy rotations, we must "stretch"
        # the ellipsoid back into a ball, which is done by
        # multiplying by sqrt_mat

        a_scaled = a * sqrt_inv_mat.transpose()
        b_scaled = b * sqrt_inv_mat.transpose()

        
        # this is to apply a Householder transformation to rotate a and b to be parallel to the y axis
        
        e = zero_vector(RR, self.dim())
        e[0] = 1
        e = vector(RR, e).column()
        refl = (e - direction.transpose()) / 2
        
        # this step might cause issues, ellipsoids are over the reals,
        # but when we multiply it by the lattice, this thing has to be rational
        # a solution is to round to the nearest rational with some precision,
        # but this can cause problems when done over and over again
        # for a single hint, this _should_ be fine, still keep note of this
        # though
        # since we are rotating and rotating back, some things should cancel out
        # intuitively, but we might have to figure this out later
        # if estimating, we need not worry about this

        G = AffineGroup(self.dim(), RR) # could be rationals, check back with this later
        if vector(RR, [a[0] for a in refl]) == zero_vector(RR, self.dim()):
            refl_mat = G(identity_matrix(self.dim()), zero_vector(RR, self.dim()))
        else:
            refl_mat = G.reflection([a[0] for a in refl])


        # Step 3: rotate the ball such that a_scaled and b_scaled are aligned
        # with the first coordinate
        # before: E = B_n
        # after: E = B_n (rotated in some way)
        a_scaled_rot = a_scaled * refl_mat.A().transpose()  + vector(RR,refl_mat.b()).row()
        b_scaled_rot = b_scaled * refl_mat.A().transpose() + vector(RR,refl_mat.b()).row()

        # now we have a unit ball with the first coordinate aligned, make sure
        # a and b are witihin this ball (since they are scalar multiples of
        # e_1, we only have to check the first coordinate)
        alpha = a_scaled_rot[0][0]
        beta = b_scaled_rot[0][0]

        alpha, beta = min(alpha, beta), max(alpha, beta)


        # in the future we might want to make it so that we assume the extreme
        # hyperplane is the tangent plane of the hypersphere
        if abs(alpha) > 1 or abs(beta) > 1:
            #raise InvalidHint("alpha or beta is too big to be useful")
            print("alpha or beta are too big to be useful")

        # this is a and b in the paper, changed names to avoid confusion
        matrix_first = 0
        matrix_rest = 0
        tau = 0
        n = self.dim()
        left_condition = 4 * n * (1 - alpha) * (1 + alpha)
        right_condition = (n + 1) * (n + 1) * (beta - alpha) * (beta + alpha)

        if alpha == -beta:
            tau = 0
            matrix_first = beta
            matrix_rest = 1
        elif left_condition < right_condition:
            tau = 0.5 * (alpha + sqrt(alpha * alpha + left_condition / pow(n + 1, 2)))
            matrix_first = tau - alpha
            matrix_rest = sqrt(matrix_first * (matrix_first + n * tau))
        else: # (left_condition >= right_condition)
            denom = 2 * (sqrt((1 - alpha) * (1 + alpha)) - sqrt((1 - beta) * (1 + beta)))
            tau = 0.5 * (beta + alpha)
            matrix_first = 0.5 * (beta - alpha)
            matrix_rest = sqrt(matrix_first ** 2 + pow((beta ** 2 - alpha ** 2) / denom, 2))
            

        # this is to build up the diagonal matrix as in the paper (LINK PAPER HERE)
        z = zero_vector(RR, n)
        z[0] = matrix_first
        for ind in range(1, n):
            z[ind] = matrix_rest
        A = diagonal_matrix(z)
        c = zero_vector(RR, n)
        c[0] = tau
        c = c.row()
        
        # Rotating the matrix to the correct orientation

        A = refl_mat.A() * A

        # transform it back and mutate the starting matrix
        # apply sqrt_inv to c
        # Dana mentioned that we might want self.S to be of the form
        # inv_sqrt_mat * S * sqrt_mat
        # because of the properties that we have
        # xSx^T <= 1 (perhaps in order to mirror this property we would have
        #    (x * sqrt_inv_mat) * S * (x * sqrt_inv_mat)^T
        # <=> x * (sqrt_inv_mat * S * inv_mat) * x^T
        
        a_s = sqrt_mat*A
        
        self.S = a_s*a_s.transpose()

        c = c * refl_mat.A().transpose() + vector(RR, refl_mat.b()).row()
        c = c * sqrt_inv_mat.transpose()
        self.mu += c
        print(self.S)
m = MIE(matrix(RR, [[3.00000000000000, 1.00000000000000], [1.00000000000000, 3.00000000000000]]), vector(RR, [0,0]).row())
create_2d_plot(m, vector(RR, [-.3, .3]).row(), -sqrt(2), sqrt(2))
